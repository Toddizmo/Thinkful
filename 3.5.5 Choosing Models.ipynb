{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which supervised learning method(s) would be best for each one of these scenarios:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Predict the running times of prospective Olympic sprinters using data from the last 20 Olympics.\n",
    "\n",
    "All model types that can predict continuous data can be used. Linear Regression, Support Vector Regression, KNN Regression, and Random Forest Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) You have more features (columns) than rows in your dataset.\n",
    "\n",
    "We used Lasso for an example that had an incredible large number of columns, so that would probably be good. Perhaps Random Forest could work or even PCA (to reduce the total number of columns). Thus gradient boosting might also be very effective, determining which features have the greatest weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Identify the most important characteristic predicting likelihood of being jailed before age 20.\n",
    "\n",
    "PCA would probably be helpful in choosing only the top features that should be used. Gradient boosting would work very well, tracking which features have the most weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Implement a filter to “highlight” emails that might be important to the recipient\n",
    "\n",
    "We did an example of this using Naive Bayes, so I assume that would be helpful (categorizing). Support Vector Classification (SVC) can be effective in seperating items into two specific categories (important or not important). SVC is a lineary binary classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) You have 1000+ features.\n",
    "\n",
    "I feel like I'd use something similar to #2, Lasso, PCA, or Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Predict whether someone who adds items to their cart on a website will purchase the items.\n",
    "\n",
    "Naive Bayes might work to classify whether someone will purchase an item. Logistic Regression is probably a better option, since the output would be a classifier (of 0 or 1) and the input could be continuous data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Your dataset dimensions are 982400 x 500\n",
    "\n",
    "You would need to reduce the number of features significantly. Lasso, PCA, gradient boosting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Identify faces in an image.\n",
    "\n",
    "Not really sure about this one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) Predict which of three flavors of ice cream will be most popular with boys vs girls.\n",
    "\n",
    "Since the input for this situation is not binary I would likely choose something like KNN classification."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
