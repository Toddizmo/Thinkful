{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\todd\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from textblob import TextBlob, Word\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('GrammarandProductReviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "      <th>dateAdded</th>\n",
       "      <th>dateUpdated</th>\n",
       "      <th>ean</th>\n",
       "      <th>keys</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>manufacturerNumber</th>\n",
       "      <th>name</th>\n",
       "      <th>...</th>\n",
       "      <th>reviews.id</th>\n",
       "      <th>reviews.numHelpful</th>\n",
       "      <th>reviews.rating</th>\n",
       "      <th>reviews.sourceURLs</th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>reviews.title</th>\n",
       "      <th>reviews.userCity</th>\n",
       "      <th>reviews.userProvince</th>\n",
       "      <th>reviews.username</th>\n",
       "      <th>upc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AV13O1A8GV-KLJ3akUyj</td>\n",
       "      <td>Universal Music</td>\n",
       "      <td>Movies, Music &amp; Books,Music,R&amp;b,Movies &amp; TV,Mo...</td>\n",
       "      <td>2017-07-25T00:52:42Z</td>\n",
       "      <td>2018-02-05T08:36:58Z</td>\n",
       "      <td>6.02537E+11</td>\n",
       "      <td>602537205981,universalmusic/14331328,universal...</td>\n",
       "      <td>Universal Music Group / Cash Money</td>\n",
       "      <td>14331328</td>\n",
       "      <td>Pink Friday: Roman Reloaded Re-Up (w/dvd)</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>https://redsky.target.com/groot-domain-api/v1/...</td>\n",
       "      <td>i love this album. it's very good. more to the...</td>\n",
       "      <td>Just Awesome</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td></td>\n",
       "      <td>Joshua</td>\n",
       "      <td>6.02537E+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AV14LG0R-jtxr-f38QfS</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>Food,Packaged Foods,Snacks,Crackers,Snacks, Co...</td>\n",
       "      <td>2017-07-25T05:16:03Z</td>\n",
       "      <td>2018-02-05T11:27:45Z</td>\n",
       "      <td>73416000391</td>\n",
       "      <td>lundbergorganiccinnamontoastricecakes/b000fvzw...</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>574764</td>\n",
       "      <td>Lundberg Organic Cinnamon Toast Rice Cakes</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00209e+08</td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>https://www.walmart.com/reviews/product/29775278</td>\n",
       "      <td>Good flavor. This review was collected as part...</td>\n",
       "      <td>Good</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Dorothy W</td>\n",
       "      <td>73416000391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AV14LG0R-jtxr-f38QfS</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>Food,Packaged Foods,Snacks,Crackers,Snacks, Co...</td>\n",
       "      <td>2017-07-25T05:16:03Z</td>\n",
       "      <td>2018-02-05T11:27:45Z</td>\n",
       "      <td>73416000391</td>\n",
       "      <td>lundbergorganiccinnamontoastricecakes/b000fvzw...</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>574764</td>\n",
       "      <td>Lundberg Organic Cinnamon Toast Rice Cakes</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00209e+08</td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>https://www.walmart.com/reviews/product/29775278</td>\n",
       "      <td>Good flavor.</td>\n",
       "      <td>Good</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Dorothy W</td>\n",
       "      <td>73416000391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AV16khLE-jtxr-f38VFn</td>\n",
       "      <td>K-Y</td>\n",
       "      <td>Personal Care,Medicine Cabinet,Lubricant/Sperm...</td>\n",
       "      <td>2017-07-25T16:26:19Z</td>\n",
       "      <td>2018-02-05T11:25:51Z</td>\n",
       "      <td>67981934427</td>\n",
       "      <td>kylovesensualitypleasuregel/b00u2whx8s,0679819...</td>\n",
       "      <td>K-Y</td>\n",
       "      <td>67981934427</td>\n",
       "      <td>K-Y Love Sensuality Pleasure Gel</td>\n",
       "      <td>...</td>\n",
       "      <td>1.13027e+08</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.walmart.com/reviews/product/43383370</td>\n",
       "      <td>I read through the reviews on here before look...</td>\n",
       "      <td>Disappointed</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Rebecca</td>\n",
       "      <td>67981934427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AV16khLE-jtxr-f38VFn</td>\n",
       "      <td>K-Y</td>\n",
       "      <td>Personal Care,Medicine Cabinet,Lubricant/Sperm...</td>\n",
       "      <td>2017-07-25T16:26:19Z</td>\n",
       "      <td>2018-02-05T11:25:51Z</td>\n",
       "      <td>67981934427</td>\n",
       "      <td>kylovesensualitypleasuregel/b00u2whx8s,0679819...</td>\n",
       "      <td>K-Y</td>\n",
       "      <td>67981934427</td>\n",
       "      <td>K-Y Love Sensuality Pleasure Gel</td>\n",
       "      <td>...</td>\n",
       "      <td>1.71268e+08</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.walmart.com/reviews/product/43383370</td>\n",
       "      <td>My husband bought this gel for us. The gel cau...</td>\n",
       "      <td>Irritation</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Walker557</td>\n",
       "      <td>67981934427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id            brand  \\\n",
       "0  AV13O1A8GV-KLJ3akUyj  Universal Music   \n",
       "1  AV14LG0R-jtxr-f38QfS         Lundberg   \n",
       "2  AV14LG0R-jtxr-f38QfS         Lundberg   \n",
       "3  AV16khLE-jtxr-f38VFn              K-Y   \n",
       "4  AV16khLE-jtxr-f38VFn              K-Y   \n",
       "\n",
       "                                          categories             dateAdded  \\\n",
       "0  Movies, Music & Books,Music,R&b,Movies & TV,Mo...  2017-07-25T00:52:42Z   \n",
       "1  Food,Packaged Foods,Snacks,Crackers,Snacks, Co...  2017-07-25T05:16:03Z   \n",
       "2  Food,Packaged Foods,Snacks,Crackers,Snacks, Co...  2017-07-25T05:16:03Z   \n",
       "3  Personal Care,Medicine Cabinet,Lubricant/Sperm...  2017-07-25T16:26:19Z   \n",
       "4  Personal Care,Medicine Cabinet,Lubricant/Sperm...  2017-07-25T16:26:19Z   \n",
       "\n",
       "            dateUpdated          ean  \\\n",
       "0  2018-02-05T08:36:58Z  6.02537E+11   \n",
       "1  2018-02-05T11:27:45Z  73416000391   \n",
       "2  2018-02-05T11:27:45Z  73416000391   \n",
       "3  2018-02-05T11:25:51Z  67981934427   \n",
       "4  2018-02-05T11:25:51Z  67981934427   \n",
       "\n",
       "                                                keys  \\\n",
       "0  602537205981,universalmusic/14331328,universal...   \n",
       "1  lundbergorganiccinnamontoastricecakes/b000fvzw...   \n",
       "2  lundbergorganiccinnamontoastricecakes/b000fvzw...   \n",
       "3  kylovesensualitypleasuregel/b00u2whx8s,0679819...   \n",
       "4  kylovesensualitypleasuregel/b00u2whx8s,0679819...   \n",
       "\n",
       "                         manufacturer manufacturerNumber  \\\n",
       "0  Universal Music Group / Cash Money           14331328   \n",
       "1                            Lundberg             574764   \n",
       "2                            Lundberg             574764   \n",
       "3                                 K-Y        67981934427   \n",
       "4                                 K-Y        67981934427   \n",
       "\n",
       "                                         name     ...        reviews.id  \\\n",
       "0   Pink Friday: Roman Reloaded Re-Up (w/dvd)     ...                     \n",
       "1  Lundberg Organic Cinnamon Toast Rice Cakes     ...       1.00209e+08   \n",
       "2  Lundberg Organic Cinnamon Toast Rice Cakes     ...       1.00209e+08   \n",
       "3            K-Y Love Sensuality Pleasure Gel     ...       1.13027e+08   \n",
       "4            K-Y Love Sensuality Pleasure Gel     ...       1.71268e+08   \n",
       "\n",
       "  reviews.numHelpful reviews.rating  \\\n",
       "0                  0              5   \n",
       "1                                 5   \n",
       "2                                 5   \n",
       "3                                 1   \n",
       "4                                 1   \n",
       "\n",
       "                                  reviews.sourceURLs  \\\n",
       "0  https://redsky.target.com/groot-domain-api/v1/...   \n",
       "1   https://www.walmart.com/reviews/product/29775278   \n",
       "2   https://www.walmart.com/reviews/product/29775278   \n",
       "3   https://www.walmart.com/reviews/product/43383370   \n",
       "4   https://www.walmart.com/reviews/product/43383370   \n",
       "\n",
       "                                        reviews.text reviews.title  \\\n",
       "0  i love this album. it's very good. more to the...  Just Awesome   \n",
       "1  Good flavor. This review was collected as part...          Good   \n",
       "2                                       Good flavor.          Good   \n",
       "3  I read through the reviews on here before look...  Disappointed   \n",
       "4  My husband bought this gel for us. The gel cau...    Irritation   \n",
       "\n",
       "  reviews.userCity  reviews.userProvince reviews.username          upc  \n",
       "0      Los Angeles                                 Joshua  6.02537E+11  \n",
       "1                                               Dorothy W  73416000391  \n",
       "2                                               Dorothy W  73416000391  \n",
       "3                                                 Rebecca  67981934427  \n",
       "4                                               Walker557  67981934427  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE create a new DataFrame called df_best_worst \n",
    "# that only contains the 5-star and 1-star reviews\n",
    "\n",
    "# ANSWER\n",
    "df_best_worst = df[(df['reviews.rating']==5) | (df['reviews.rating']==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "      <th>dateAdded</th>\n",
       "      <th>dateUpdated</th>\n",
       "      <th>ean</th>\n",
       "      <th>keys</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>manufacturerNumber</th>\n",
       "      <th>name</th>\n",
       "      <th>...</th>\n",
       "      <th>reviews.id</th>\n",
       "      <th>reviews.numHelpful</th>\n",
       "      <th>reviews.rating</th>\n",
       "      <th>reviews.sourceURLs</th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>reviews.title</th>\n",
       "      <th>reviews.userCity</th>\n",
       "      <th>reviews.userProvince</th>\n",
       "      <th>reviews.username</th>\n",
       "      <th>upc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AV13O1A8GV-KLJ3akUyj</td>\n",
       "      <td>Universal Music</td>\n",
       "      <td>Movies, Music &amp; Books,Music,R&amp;b,Movies &amp; TV,Mo...</td>\n",
       "      <td>2017-07-25T00:52:42Z</td>\n",
       "      <td>2018-02-05T08:36:58Z</td>\n",
       "      <td>6.02537E+11</td>\n",
       "      <td>602537205981,universalmusic/14331328,universal...</td>\n",
       "      <td>Universal Music Group / Cash Money</td>\n",
       "      <td>14331328</td>\n",
       "      <td>Pink Friday: Roman Reloaded Re-Up (w/dvd)</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>https://redsky.target.com/groot-domain-api/v1/...</td>\n",
       "      <td>i love this album. it's very good. more to the...</td>\n",
       "      <td>Just Awesome</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td></td>\n",
       "      <td>Joshua</td>\n",
       "      <td>6.02537E+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AV14LG0R-jtxr-f38QfS</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>Food,Packaged Foods,Snacks,Crackers,Snacks, Co...</td>\n",
       "      <td>2017-07-25T05:16:03Z</td>\n",
       "      <td>2018-02-05T11:27:45Z</td>\n",
       "      <td>73416000391</td>\n",
       "      <td>lundbergorganiccinnamontoastricecakes/b000fvzw...</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>574764</td>\n",
       "      <td>Lundberg Organic Cinnamon Toast Rice Cakes</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00209e+08</td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>https://www.walmart.com/reviews/product/29775278</td>\n",
       "      <td>Good flavor. This review was collected as part...</td>\n",
       "      <td>Good</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Dorothy W</td>\n",
       "      <td>73416000391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AV14LG0R-jtxr-f38QfS</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>Food,Packaged Foods,Snacks,Crackers,Snacks, Co...</td>\n",
       "      <td>2017-07-25T05:16:03Z</td>\n",
       "      <td>2018-02-05T11:27:45Z</td>\n",
       "      <td>73416000391</td>\n",
       "      <td>lundbergorganiccinnamontoastricecakes/b000fvzw...</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>574764</td>\n",
       "      <td>Lundberg Organic Cinnamon Toast Rice Cakes</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00209e+08</td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>https://www.walmart.com/reviews/product/29775278</td>\n",
       "      <td>Good flavor.</td>\n",
       "      <td>Good</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Dorothy W</td>\n",
       "      <td>73416000391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AV16khLE-jtxr-f38VFn</td>\n",
       "      <td>K-Y</td>\n",
       "      <td>Personal Care,Medicine Cabinet,Lubricant/Sperm...</td>\n",
       "      <td>2017-07-25T16:26:19Z</td>\n",
       "      <td>2018-02-05T11:25:51Z</td>\n",
       "      <td>67981934427</td>\n",
       "      <td>kylovesensualitypleasuregel/b00u2whx8s,0679819...</td>\n",
       "      <td>K-Y</td>\n",
       "      <td>67981934427</td>\n",
       "      <td>K-Y Love Sensuality Pleasure Gel</td>\n",
       "      <td>...</td>\n",
       "      <td>1.13027e+08</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.walmart.com/reviews/product/43383370</td>\n",
       "      <td>I read through the reviews on here before look...</td>\n",
       "      <td>Disappointed</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Rebecca</td>\n",
       "      <td>67981934427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AV16khLE-jtxr-f38VFn</td>\n",
       "      <td>K-Y</td>\n",
       "      <td>Personal Care,Medicine Cabinet,Lubricant/Sperm...</td>\n",
       "      <td>2017-07-25T16:26:19Z</td>\n",
       "      <td>2018-02-05T11:25:51Z</td>\n",
       "      <td>67981934427</td>\n",
       "      <td>kylovesensualitypleasuregel/b00u2whx8s,0679819...</td>\n",
       "      <td>K-Y</td>\n",
       "      <td>67981934427</td>\n",
       "      <td>K-Y Love Sensuality Pleasure Gel</td>\n",
       "      <td>...</td>\n",
       "      <td>1.71268e+08</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.walmart.com/reviews/product/43383370</td>\n",
       "      <td>My husband bought this gel for us. The gel cau...</td>\n",
       "      <td>Irritation</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Walker557</td>\n",
       "      <td>67981934427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id            brand  \\\n",
       "0  AV13O1A8GV-KLJ3akUyj  Universal Music   \n",
       "1  AV14LG0R-jtxr-f38QfS         Lundberg   \n",
       "2  AV14LG0R-jtxr-f38QfS         Lundberg   \n",
       "3  AV16khLE-jtxr-f38VFn              K-Y   \n",
       "4  AV16khLE-jtxr-f38VFn              K-Y   \n",
       "\n",
       "                                          categories             dateAdded  \\\n",
       "0  Movies, Music & Books,Music,R&b,Movies & TV,Mo...  2017-07-25T00:52:42Z   \n",
       "1  Food,Packaged Foods,Snacks,Crackers,Snacks, Co...  2017-07-25T05:16:03Z   \n",
       "2  Food,Packaged Foods,Snacks,Crackers,Snacks, Co...  2017-07-25T05:16:03Z   \n",
       "3  Personal Care,Medicine Cabinet,Lubricant/Sperm...  2017-07-25T16:26:19Z   \n",
       "4  Personal Care,Medicine Cabinet,Lubricant/Sperm...  2017-07-25T16:26:19Z   \n",
       "\n",
       "            dateUpdated          ean  \\\n",
       "0  2018-02-05T08:36:58Z  6.02537E+11   \n",
       "1  2018-02-05T11:27:45Z  73416000391   \n",
       "2  2018-02-05T11:27:45Z  73416000391   \n",
       "3  2018-02-05T11:25:51Z  67981934427   \n",
       "4  2018-02-05T11:25:51Z  67981934427   \n",
       "\n",
       "                                                keys  \\\n",
       "0  602537205981,universalmusic/14331328,universal...   \n",
       "1  lundbergorganiccinnamontoastricecakes/b000fvzw...   \n",
       "2  lundbergorganiccinnamontoastricecakes/b000fvzw...   \n",
       "3  kylovesensualitypleasuregel/b00u2whx8s,0679819...   \n",
       "4  kylovesensualitypleasuregel/b00u2whx8s,0679819...   \n",
       "\n",
       "                         manufacturer manufacturerNumber  \\\n",
       "0  Universal Music Group / Cash Money           14331328   \n",
       "1                            Lundberg             574764   \n",
       "2                            Lundberg             574764   \n",
       "3                                 K-Y        67981934427   \n",
       "4                                 K-Y        67981934427   \n",
       "\n",
       "                                         name     ...        reviews.id  \\\n",
       "0   Pink Friday: Roman Reloaded Re-Up (w/dvd)     ...                     \n",
       "1  Lundberg Organic Cinnamon Toast Rice Cakes     ...       1.00209e+08   \n",
       "2  Lundberg Organic Cinnamon Toast Rice Cakes     ...       1.00209e+08   \n",
       "3            K-Y Love Sensuality Pleasure Gel     ...       1.13027e+08   \n",
       "4            K-Y Love Sensuality Pleasure Gel     ...       1.71268e+08   \n",
       "\n",
       "  reviews.numHelpful reviews.rating  \\\n",
       "0                  0              5   \n",
       "1                                 5   \n",
       "2                                 5   \n",
       "3                                 1   \n",
       "4                                 1   \n",
       "\n",
       "                                  reviews.sourceURLs  \\\n",
       "0  https://redsky.target.com/groot-domain-api/v1/...   \n",
       "1   https://www.walmart.com/reviews/product/29775278   \n",
       "2   https://www.walmart.com/reviews/product/29775278   \n",
       "3   https://www.walmart.com/reviews/product/43383370   \n",
       "4   https://www.walmart.com/reviews/product/43383370   \n",
       "\n",
       "                                        reviews.text reviews.title  \\\n",
       "0  i love this album. it's very good. more to the...  Just Awesome   \n",
       "1  Good flavor. This review was collected as part...          Good   \n",
       "2                                       Good flavor.          Good   \n",
       "3  I read through the reviews on here before look...  Disappointed   \n",
       "4  My husband bought this gel for us. The gel cau...    Irritation   \n",
       "\n",
       "  reviews.userCity  reviews.userProvince reviews.username          upc  \n",
       "0      Los Angeles                                 Joshua  6.02537E+11  \n",
       "1                                               Dorothy W  73416000391  \n",
       "2                                               Dorothy W  73416000391  \n",
       "3                                                 Rebecca  67981934427  \n",
       "4                                               Walker557  67981934427  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_best_worst.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    46543\n",
      "1     3701\n",
      "Name: reviews.rating, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# define X and y\n",
    "X = df_best_worst['reviews.text']\n",
    "y = df_best_worst['reviews.rating']\n",
    "print (y.value_counts())\n",
    "\n",
    "# split the new DataFrame into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31301    I was pretty skeptical about this product at f...\n",
       "40514    Love this move. Great for kids and adults of a...\n",
       "42102    This movie turned out to be one of the funnies...\n",
       "58710    Easy to apply, absorbs well. Could feel my ski...\n",
       "43635    Great movie. Fun for all ages. 3D is also done...\n",
       "Name: reviews.text, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Tokenization\n",
    "\n",
    "- **What:** Separate text into units such as sentences or words\n",
    "- **Why:** Gives structure to previously unstructured text\n",
    "- **Notes:** Relatively easy with English language text, not easy with some languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example documents\n",
    "simple_train = ['call you tonight', 'Call me a cab', 'please call me... PLEASE!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>me</th>\n",
       "      <th>please</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cab  call  me  please  tonight  you\n",
       "0    0     1   0       0        1    1\n",
       "1    1     1   1       0        0    0\n",
       "2    0     1   1       2        0    0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Term Frequency\n",
    "vect = CountVectorizer()\n",
    "tf = pd.DataFrame(vect.fit_transform(simple_train).toarray(), columns=vect.get_feature_names())\n",
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>me</th>\n",
       "      <th>please</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cab  call  me  please  tonight  you\n",
       "0    1     1   0       1        0    0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transforming a new sentence, what do you notice?\n",
    "pd.DataFrame(vect.transform(['please call yourself a cab']).toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use CountVectorizer to create document-term matrices from X_train and X_test\n",
    "vect = CountVectorizer()\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37683, 19919)\n",
      "(12561, 19919)\n"
     ]
    }
   ],
   "source": [
    "# rows are documents, columns are terms (phrases) (aka \"tokens\" or \"features\")\n",
    "print (X_train_dtm.shape)\n",
    "print (X_test_dtm.shape)\n",
    "# Why do they have the same number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '000', '0000', '000x', '007', '02', '05', '07', '09', '0layus', '0real', '10', '100', '1000', '10000000000', '1007', '100ml', '100oz', '100s', '100x', '102', '103', '104', '1040', '105', '1080', '1080p', '1099s', '10am', '10c', '10days', '10dlls', '10min', '10mo', '10mth', '10x', '10xs', '10year', '10yrs', '11', '110', '113', '11438', '1183', '11th', '11x14', '11yr', '12', '120', '1200']\n"
     ]
    }
   ],
   "source": [
    "# first 50 features\n",
    "print (vect.get_feature_names()[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ypo', 'yr', 'yrs', 'ysl', 'yu', 'yuck', 'yuckiness', 'yucko', 'yucky', 'yuk', 'yum', 'yuma', 'yumm', 'yummm', 'yummy', 'yup', 'yyears', 'zac', 'zach', 'zack', 'zany', 'zeiss', 'zero', 'zest', 'zilla', 'zinc', 'zing', 'zip', 'zipcode', 'ziploc', 'ziplock', 'zipper', 'zippers', 'zit', 'ziti', 'zits', 'zitz', 'zojirushi', 'zombie', 'zombies', 'zone', 'zones', 'zoo', 'zoom', 'zootopia', 'zre', 'zucchetta', 'zucchini', 'zyliss', 'zyrtec']\n"
     ]
    }
   ],
   "source": [
    "# last 50 features\n",
    "print (vect.get_feature_names()[-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show vectorizer options\n",
    "vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **ngram_range:** tuple (min_n, max_n)\n",
    "- The lower and upper boundary of the range of n-values for different n-grams to be extracted. All values of n such that min_n <= n <= max_n will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9747631557996975\n"
     ]
    }
   ],
   "source": [
    "# use default options for CountVectorizer\n",
    "vect = CountVectorizer()\n",
    "\n",
    "# create document-term matrices :: only single words\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "\n",
    "# use logistic regression with document feature matrix, NOT the text column\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_dtm, y_train)\n",
    "y_pred_class = logreg.predict(X_test_dtm)\n",
    "\n",
    "# calculate accuracy\n",
    "print (metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9242098559031924"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate null accuracy, which is the accuracy of our null model (just guessing the most common thing)\n",
    "y_test_binary = np.where(y_test==5, 1, 0)\n",
    "max(y_test_binary.mean(), 1 - y_test_binary.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function does 5 things\n",
    "# Has a single input, vect, that is a countvectorizer\n",
    "# instantiates a logistic regression\n",
    "# fit_transforms X using the vectorizer\n",
    "# print the number of features (phrases)\n",
    "# prints the output of a 5 fold cross validation using accuracy as our metric\n",
    "def tokenize_test(vect):\n",
    "    logreg = LogisticRegression()\n",
    "    X_dtm = vect.fit_transform(X)\n",
    "    print ('Features: ', X_dtm.shape[1])\n",
    "    print ('Accuracy: ', cross_val_score(logreg, X_dtm, y, cv=5, scoring='accuracy').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  337182\n",
      "Accuracy:  0.9651496242314644\n"
     ]
    }
   ],
   "source": [
    "# include 1-grams and 2-grams\n",
    "vect = CountVectorizer(ngram_range=(1, 2))\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Stopword Removal\n",
    "\n",
    "- **What:** Remove common words that will likely appear in any text\n",
    "- **Why:** They don't tell you much about your text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show vectorizer options\n",
    "vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **stop_words:** string {'english'}, list, or None (default)\n",
    "- If 'english', a built-in stop word list for English is used.\n",
    "- If a list, that list is assumed to contain stop words, all of which will be removed from the resulting tokens.\n",
    "- If None, no stop words will be used. max_df can be set to a value in the range [0.7, 1.0) to automatically detect and filter stop words based on intra corpus document frequency of terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  345993\n",
      "Accuracy:  0.9585217900957079\n"
     ]
    }
   ],
   "source": [
    "# remove English stop words\n",
    "vect = CountVectorizer(stop_words='english', ngram_range=(1, 2))\n",
    "tokenize_test(vect)\n",
    "# made predictions worse! Why? - we're not using stop words anymore, which are the most common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({'fill', 'therein', 'about', 'anyone', 'please', 'its', 'sixty', 'sincere', 'due', 'de', 'afterwards', 'has', 'many', 'nobody', 'move', 'of', 'some', 'even', 'name', 'namely', 'their', 'top', 'anywhere', 'mine', 'amongst', 'empty', 'hereupon', 'any', 'least', 'very', 'something', 'eg', 'while', 'too', 'as', 'never', 'by', 'ourselves', 'the', 'thereby', 'whether', 'both', 'in', 'mill', 'or', 'because', 'above', 'after', 'four', 'hers', 'same', 'am', 'how', 'without', 'him', 'former', 'seemed', 'yours', 'beyond', 're', 'beforehand', 'do', 'wherein', 'amoungst', 'few', 'around', 'therefore', 'cry', 'front', 'between', 'next', 'although', 'can', 'everything', 'i', 'thus', 'why', 'couldnt', 'must', 'under', 'ever', 'wherever', 'another', 'be', 'beside', 'other', 'may', 'forty', 'neither', 'twelve', 'always', 'hereafter', 'but', 'becoming', 'everyone', 'ltd', 'it', 'will', 'out', 'yet', 'is', 'toward', 'himself', 'onto', 'less', 'either', 'not', 'yourselves', 'an', 'interest', 'were', 'one', 'within', 'cant', 'latter', 'myself', 'else', 'nothing', 'nevertheless', 'been', 'nor', 'per', 'otherwise', 'system', 'you', 'keep', 'etc', 'further', 'whoever', 'whole', 'perhaps', 'these', 'all', 'with', 'co', 'against', 'often', 'besides', 'became', 'un', 'noone', 'hasnt', 'itself', 'yourself', 'she', 'seeming', 'give', 'mostly', 'bottom', 'hence', 'along', 'call', 'once', 'throughout', 'own', 'ten', 'during', 'first', 'he', 'moreover', 'they', 'might', 'only', 'every', 'third', 'eleven', 'more', 'our', 'find', 'being', 'there', 'whither', 'somehow', 'hundred', 'thence', 'eight', 'to', 'into', 'when', 'seem', 'made', 'back', 'below', 'con', 'take', 'show', 'thick', 'since', 'this', 'whereby', 'describe', 'thru', 'at', 'whereupon', 'someone', 'whom', 'cannot', 'inc', 'bill', 'whence', 'whereas', 'well', 'part', 'get', 'indeed', 'what', 'whose', 'full', 'latterly', 'my', 'now', 'see', 'several', 'that', 'almost', 'than', 'his', 'enough', 'hereby', 'whatever', 'already', 'herein', 'towards', 'six', 'however', 'last', 'could', 'anyway', 'ie', 'put', 'themselves', 'which', 'her', 'fifteen', 'rather', 'amount', 'serious', 'have', 'done', 'a', 'alone', 'should', 'somewhere', 'nine', 'then', 'us', 'go', 'five', 'those', 'fifty', 'from', 'nowhere', 'twenty', 'across', 'here', 'though', 'through', 'are', 'three', 'elsewhere', 'each', 'found', 'thin', 'who', 'we', 'none', 'off', 'ours', 'most', 'whereafter', 'thereafter', 'others', 'anything', 'me', 'anyhow', 'your', 'again', 'except', 'become', 'formerly', 'for', 'over', 'thereupon', 'among', 'on', 'side', 'behind', 'no', 'herself', 'becomes', 'so', 'whenever', 'sometimes', 'together', 'via', 'them', 'two', 'detail', 'fire', 'seems', 'much', 'also', 'had', 'upon', 'down', 'where', 'until', 'everywhere', 'would', 'was', 'and', 'sometime', 'before', 'up', 'still', 'meanwhile', 'if', 'such'})\n"
     ]
    }
   ],
   "source": [
    "# set of stop words\n",
    "print (vect.get_stop_words())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Other CountVectorizer Options\n",
    "\n",
    "- **max_features:** int or None, default=None\n",
    "- If not None, build a vocabulary that only consider the top max_features ordered by term frequency across the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  100\n",
      "Accuracy:  0.9362497486805259\n"
     ]
    }
   ],
   "source": [
    "# remove English stop words and only keep 100 features, should be substantially FASTER\n",
    "vect = CountVectorizer(stop_words='english', max_features=100)\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amazing', 'awesome', 'bathroom', 'best', 'better', 'bought', 'buy', 'clean', 'cleaning', 'clorox', 'clothes', 'collected', 'color', 'conditioner', 'day', 'definitely', 'detergent', 'did', 'didn', 'does', 'doesn', 'don', 'dry', 'easy', 'effects', 'enjoyed', 'face', 'family', 'favorite', 'feel', 'feels', 'formula', 'free', 'fresh', 'funny', 'good', 'got', 'great', 'hair', 'home', 'house', 'job', 'just', 'kids', 'kitchen', 'know', 'laundry', 'like', 'little', 'long', 'look', 'looking', 'lot', 'love', 'loved', 'make', 'makes', 'moisturizer', 'mop', 'movie', 'movies', 'need', 'new', 'nice', 'olay', 'old', 'original', 'perfect', 'pods', 'price', 'product', 'products', 'promotion', 'really', 'received', 'recommend', 'review', 'scent', 'shampoo', 'skin', 'smell', 'smells', 'smooth', 'soft', 'think', 'tide', 'time', 'tried', 'try', 'use', 'used', 'using', 've', 'watch', 'way', 'wipes', 'wonderful', 'work', 'works', 'years']\n"
     ]
    }
   ],
   "source": [
    "# all 100 features\n",
    "print (vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  100000\n",
      "Accuracy:  0.9652889336539072\n"
     ]
    }
   ],
   "source": [
    "# include 1-grams and 2-grams, and limit the number of features\n",
    "vect = CountVectorizer(ngram_range=(1, 2), max_features=100000)\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **min_df:** float in range [0.0, 1.0] or int, default=1\n",
    "- When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold. This value is also called cut-off in the literature. If float, the parameter represents a proportion of documents, integer absolute counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Introduction to TextBlob\n",
    "\n",
    "TextBlob: \"Simplified Text Processing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love this album. it's very good. more to the hip hop side than her current pop sound.. SO HYPE! i listen to this everyday at the gym! i give it 5star rating all the way. her metaphors are just crazy.\n"
     ]
    }
   ],
   "source": [
    "# print the first review\n",
    "print (df_best_worst['reviews.text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save it as a TextBlob object\n",
    "review = TextBlob(df_best_worst['reviews.text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['i', 'love', 'this', 'album', 'it', \"'s\", 'very', 'good', 'more', 'to', 'the', 'hip', 'hop', 'side', 'than', 'her', 'current', 'pop', 'sound', 'SO', 'HYPE', 'i', 'listen', 'to', 'this', 'everyday', 'at', 'the', 'gym', 'i', 'give', 'it', '5star', 'rating', 'all', 'the', 'way', 'her', 'metaphors', 'are', 'just', 'crazy'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list the words\n",
    "review.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"i love this album.\"),\n",
       " Sentence(\"it's very good.\"),\n",
       " Sentence(\"more to the hip hop side than her current pop sound..\"),\n",
       " Sentence(\"SO HYPE!\"),\n",
       " Sentence(\"i listen to this everyday at the gym!\"),\n",
       " Sentence(\"i give it 5star rating all the way.\"),\n",
       " Sentence(\"her metaphors are just crazy.\")]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list the sentences\n",
    "review.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"i love this album. it's very good. more to the hip hop side than her current pop sound.. so hype! i listen to this everyday at the gym! i give it 5star rating all the way. her metaphors are just crazy.\")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some string methods are available\n",
    "review.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Stemming and Lemmatization\n",
    "\n",
    "**Stemming:**\n",
    "\n",
    "- **What:** Reduce a word to its base/stem/root form\n",
    "- **Why:** Often makes sense to treat related words the same way\n",
    "- **Notes:**\n",
    "    - Uses a \"simple\" and fast rule-based approach\n",
    "    - Stemmed words are usually not shown to users (used for analysis/indexing)\n",
    "    - Some search engines treat words with the same stem as synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'love', 'this', 'album', 'it', \"'s\", 'veri', 'good', 'more', 'to', 'the', 'hip', 'hop', 'side', 'than', 'her', 'current', 'pop', 'sound', 'so', 'hype', 'i', 'listen', 'to', 'this', 'everyday', 'at', 'the', 'gym', 'i', 'give', 'it', '5star', 'rate', 'all', 'the', 'way', 'her', 'metaphor', 'are', 'just', 'crazi']\n"
     ]
    }
   ],
   "source": [
    "# initialize stemmer\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "# stem each word\n",
    "print ([stemmer.stem(word) for word in review.words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lemmatization**\n",
    "\n",
    "- **What:** Derive the canonical form ('lemma') of a word\n",
    "- **Why:** Can be better than stemming\n",
    "- **Notes:** Uses a dictionary-based approach (slower than stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = Word('wolves')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wolv'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'love', 'this', 'album', 'it', \"'s\", 'very', 'good', 'more', 'to', 'the', 'hip', 'hop', 'side', 'than', 'her', 'current', 'pop', 'sound', 'SO', 'HYPE', 'i', 'listen', 'to', 'this', 'everyday', 'at', 'the', 'gym', 'i', 'give', 'it', '5star', 'rating', 'all', 'the', 'way', 'her', 'metaphor', 'are', 'just', 'crazy']\n"
     ]
    }
   ],
   "source": [
    "# assume every word is a noun\n",
    "print ([word.lemmatize() for word in review.words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'love', 'this', 'album', 'it', \"'s\", 'very', 'good', 'more', 'to', 'the', 'hip', 'hop', 'side', 'than', 'her', 'current', 'pop', 'sound', 'SO', 'HYPE', 'i', 'listen', 'to', 'this', 'everyday', 'at', 'the', 'gym', 'i', 'give', 'it', '5star', 'rat', 'all', 'the', 'way', 'her', 'metaphors', 'be', 'just', 'crazy']\n"
     ]
    }
   ],
   "source": [
    "# assume every word is a verb\n",
    "print ([word.lemmatize(pos='v') for word in review.words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that accepts text and returns a list of lemmas\n",
    "def word_tokenize(text, how='lemma'):\n",
    "    words = TextBlob(text).words\n",
    "    if how == 'lemma':\n",
    "        return [word.lemmatize() for word in words]\n",
    "    elif how == 'stem':\n",
    "        return [stemmer.stem(word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  31414\n",
      "Accuracy:  0.9590791089989817\n"
     ]
    }
   ],
   "source": [
    "# use word_tokenize LEMMA as the feature extraction function (WARNING: SLOW!)\n",
    "# this will lemmatize each word\n",
    "vect = CountVectorizer(analyzer=lambda x:word_tokenize(x, how='lemma'))\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  19359\n",
      "Accuracy:  0.9577853805930117\n"
     ]
    }
   ],
   "source": [
    "# use word_tokenize STEM as the feature extraction function (WARNING: SLOW!)\n",
    "# this will lemmatize each word\n",
    "vect = CountVectorizer(analyzer=lambda x:word_tokenize(x, how='stem'))\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Term Frequency-Inverse Document Frequency (TF-IDF)\n",
    "\n",
    "- **What:** Computes \"relative frequency\" that a word appears in a document compared to its frequency across all documents\n",
    "- **Why:** More useful than \"term frequency\" for identifying \"important\" words in each document (high frequency in that document, low frequency in other documents)\n",
    "- **Notes:** Used for search engine scoring, text summarization, document clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example documents\n",
    "simple_train = ['call you tonight', 'Call me a cab', 'please call me... PLEASE!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>me</th>\n",
       "      <th>please</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cab  call  me  please  tonight  you\n",
       "0    0     1   0       0        1    1\n",
       "1    1     1   1       0        0    0\n",
       "2    0     1   1       2        0    0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Term Frequency\n",
    "vect = CountVectorizer()\n",
    "tf = pd.DataFrame(vect.fit_transform(simple_train).toarray(), columns=vect.get_feature_names())\n",
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>me</th>\n",
       "      <th>please</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cab  call  me  please  tonight  you\n",
       "0    1     3   2       1        1    1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Document Frequency\n",
    "vect = CountVectorizer(binary=True)\n",
    "df2 = vect.fit_transform(simple_train).toarray().sum(axis=0)\n",
    "pd.DataFrame(df2.reshape(1, 6), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>me</th>\n",
       "      <th>please</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cab      call   me  please  tonight  you\n",
       "0  0.0  0.333333  0.0     0.0      1.0  1.0\n",
       "1  1.0  0.333333  0.5     0.0      0.0  0.0\n",
       "2  0.0  0.333333  0.5     2.0      0.0  0.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Term Frequency-Inverse Document Frequency (simple version)\n",
    "tf/df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>me</th>\n",
       "      <th>please</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.652491</td>\n",
       "      <td>0.652491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.720333</td>\n",
       "      <td>0.425441</td>\n",
       "      <td>0.547832</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266075</td>\n",
       "      <td>0.342620</td>\n",
       "      <td>0.901008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        cab      call        me    please   tonight       you\n",
       "0  0.000000  0.385372  0.000000  0.000000  0.652491  0.652491\n",
       "1  0.720333  0.425441  0.547832  0.000000  0.000000  0.000000\n",
       "2  0.000000  0.266075  0.342620  0.901008  0.000000  0.000000"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TfidfVectorizer\n",
    "vect = TfidfVectorizer()\n",
    "pd.DataFrame(vect.fit_transform(simple_train).toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71044, 26958)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a document-term matrix using TF-IDF\n",
    "vect = TfidfVectorizer(stop_words='english')\n",
    "dtm = vect.fit_transform(df['reviews.text'])\n",
    "features = vect.get_feature_names()\n",
    "dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  22344\n",
      "Accuracy:  0.9574074751348396\n"
     ]
    }
   ],
   "source": [
    "vect = TfidfVectorizer(stop_words='english')\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Using TF-IDF to Summarize a Review\n",
    "\n",
    "Reddit's autotldr uses the [SMMRY](http://smmry.com/about) algorithm, which is based on TF-IDF!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"    # print 5 random words\\n    print ('\\n' + 'RANDOM WORDS:')\\n    random_words = np.random.choice(word_scores.keys(), size=5, replace=False)\\n    for word in random_words:\\n        print (word)\\n    # print the review\\n    print ('\\n' + review_text)\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def summarize():\n",
    "    \n",
    "    # choose a random review that is at least 300 characters\n",
    "    review_length = 0\n",
    "    while review_length < 300:\n",
    "        review_id = np.random.randint(0, len(df))\n",
    "        review_text = df['reviews.text'][review_id]\n",
    "        review_length = len(review_text)\n",
    "    \n",
    "    # create a dictionary of words and their TF-IDF scores\n",
    "    word_scores = {}\n",
    "    for word in TextBlob(review_text).words:\n",
    "        word = word.lower()\n",
    "        if word in features:\n",
    "            word_scores[word] = dtm[review_id, features.index(word)]\n",
    "    \n",
    "    # print words with the top 5 TF-IDF scores\n",
    "    print ('TOP SCORING WORDS:')\n",
    "    top_scores = sorted(word_scores.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "    for word, score in top_scores:\n",
    "        print (word)\n",
    "\n",
    "# portion did not function correctly\n",
    "            \n",
    "'''    # print 5 random words\n",
    "    print ('\\n' + 'RANDOM WORDS:')\n",
    "    random_words = np.random.choice(word_scores.keys(), size=5, replace=False)\n",
    "    for word in random_words:\n",
    "        print (word)\n",
    "    # print the review\n",
    "    print ('\\n' + review_text)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP SCORING WORDS:\n",
      "tide\n",
      "phyical\n",
      "husband\n",
      "satified\n",
      "wringer\n"
     ]
    }
   ],
   "source": [
    "summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9: Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love this album. it's very good. more to the hip hop side than her current pop sound.. SO HYPE! i listen to this everyday at the gym! i give it 5star rating all the way. her metaphors are just crazy.\n"
     ]
    }
   ],
   "source": [
    "print (review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22285714285714286"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# polarity ranges from -1 (most negative) to 1 (most positive)\n",
    "review.sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "      <th>dateAdded</th>\n",
       "      <th>dateUpdated</th>\n",
       "      <th>ean</th>\n",
       "      <th>keys</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>manufacturerNumber</th>\n",
       "      <th>name</th>\n",
       "      <th>...</th>\n",
       "      <th>reviews.numHelpful</th>\n",
       "      <th>reviews.rating</th>\n",
       "      <th>reviews.sourceURLs</th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>reviews.title</th>\n",
       "      <th>reviews.userCity</th>\n",
       "      <th>reviews.userProvince</th>\n",
       "      <th>reviews.username</th>\n",
       "      <th>upc</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AV13O1A8GV-KLJ3akUyj</td>\n",
       "      <td>Universal Music</td>\n",
       "      <td>Movies, Music &amp; Books,Music,R&amp;b,Movies &amp; TV,Mo...</td>\n",
       "      <td>2017-07-25T00:52:42Z</td>\n",
       "      <td>2018-02-05T08:36:58Z</td>\n",
       "      <td>6.02537E+11</td>\n",
       "      <td>602537205981,universalmusic/14331328,universal...</td>\n",
       "      <td>Universal Music Group / Cash Money</td>\n",
       "      <td>14331328</td>\n",
       "      <td>Pink Friday: Roman Reloaded Re-Up (w/dvd)</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>https://redsky.target.com/groot-domain-api/v1/...</td>\n",
       "      <td>i love this album. it's very good. more to the...</td>\n",
       "      <td>Just Awesome</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td></td>\n",
       "      <td>Joshua</td>\n",
       "      <td>6.02537E+11</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id            brand  \\\n",
       "0  AV13O1A8GV-KLJ3akUyj  Universal Music   \n",
       "\n",
       "                                          categories             dateAdded  \\\n",
       "0  Movies, Music & Books,Music,R&b,Movies & TV,Mo...  2017-07-25T00:52:42Z   \n",
       "\n",
       "            dateUpdated          ean  \\\n",
       "0  2018-02-05T08:36:58Z  6.02537E+11   \n",
       "\n",
       "                                                keys  \\\n",
       "0  602537205981,universalmusic/14331328,universal...   \n",
       "\n",
       "                         manufacturer manufacturerNumber  \\\n",
       "0  Universal Music Group / Cash Money           14331328   \n",
       "\n",
       "                                        name  ...   reviews.numHelpful  \\\n",
       "0  Pink Friday: Roman Reloaded Re-Up (w/dvd)  ...                    0   \n",
       "\n",
       "  reviews.rating                                 reviews.sourceURLs  \\\n",
       "0              5  https://redsky.target.com/groot-domain-api/v1/...   \n",
       "\n",
       "                                        reviews.text reviews.title  \\\n",
       "0  i love this album. it's very good. more to the...  Just Awesome   \n",
       "\n",
       "  reviews.userCity reviews.userProvince  reviews.username          upc length  \n",
       "0      Los Angeles                                 Joshua  6.02537E+11    201  \n",
       "\n",
       "[1 rows x 26 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# understanding the apply method\n",
    "df['length'] = df['reviews.text'].apply(len)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x169000b0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show a histogram of df review lengths\n",
    "df['length'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that accepts text and returns the polarity\n",
    "def detect_sentiment(text):\n",
    "    return TextBlob(text).sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new DataFrame column for sentiment (WARNING: SLOW!)\n",
    "df['sentiment'] = df['reviews.text'].apply(detect_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a box plot of sentiment grouped by stars and a histogram of yelp sentiment\n",
    "# You should have five boxplots in the same graph for sentiment for the first graph\n",
    "# df.boxplot(column='sentiment', by='reviews.text')\n",
    "\n",
    "# slow code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['sentiment'].hist() # Mostly positive!\n",
    "\n",
    "# slow code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208    The best moisturizer I have used. The results ...\n",
       "215    Very happy with this product and would recomme...\n",
       "312    Until I found this product I was feeling hopel...\n",
       "404    I have used for a couple of years and are very...\n",
       "484    This product is wonderful and have recommended...\n",
       "Name: reviews.text, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the reviews with most positive sentiment (a score of 1)\n",
    "df[df.sentiment == 1]['reviews.text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1831    This was a boring movie i couldnt watch 20 min...\n",
       "1904    Not the funniest movie ive ever seen but def n...\n",
       "2622    My fiance likes these movies for some reason. ...\n",
       "3700    i aways bought the xxx but can not find it so ...\n",
       "5119    A must have for any Resident Evil enthusiast, ...\n",
       "Name: reviews.text, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reviews with most negative sentiment\n",
    "df[df.sentiment == -1]['reviews.text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# widen the column display\n",
    "pd.set_option('max_colwidth', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "      <th>dateAdded</th>\n",
       "      <th>dateUpdated</th>\n",
       "      <th>ean</th>\n",
       "      <th>keys</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>manufacturerNumber</th>\n",
       "      <th>name</th>\n",
       "      <th>...</th>\n",
       "      <th>reviews.rating</th>\n",
       "      <th>reviews.sourceURLs</th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>reviews.title</th>\n",
       "      <th>reviews.userCity</th>\n",
       "      <th>reviews.userProvince</th>\n",
       "      <th>reviews.username</th>\n",
       "      <th>upc</th>\n",
       "      <th>length</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>AV1YGDqsGV-KLJ3adc-O</td>\n",
       "      <td>Windex</td>\n",
       "      <td>Household Essentials,Cleaning Supplies,Glass Cleaners,Health &amp; Household,Household Supplies,Household Cleaning,Featured Brands,Home And Storage &amp; Org,Thanksgathering,All-purpose Cleaners,Target Restock,Food &amp; Grocery,Glass &amp; Window</td>\n",
       "      <td>2017-07-18T23:46:09Z</td>\n",
       "      <td>2018-02-05T08:34:58Z</td>\n",
       "      <td>19800001285</td>\n",
       "      <td>019800001285,windex/12972711,windexoriginalglasscleanerrefill676oz2liter/b00192ex24,windexoriginalglasscleanerrefill676oz2liter/b000v9lapy,windexoriginalglasscleanerrefill676oz2liter/b000v9qn1a,windexoriginalglasscleanerrefill676oz2liter/001309400,windexoriginalglasscleanerrefill676oz2liter/1309400,windexoriginalglasscleanerrefill676oz2liter/03249461000p,0019800001285</td>\n",
       "      <td>Windex</td>\n",
       "      <td>12972711</td>\n",
       "      <td>Windex Original Glass Cleaner Refill 67.6oz (2 Liter)</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>https://www.walmart.com/reviews/product/11027259?limit=20&amp;sort=relevancy&amp;page=12,https://www.walmart.com/reviews/product/11027259?limit=20&amp;sort=relevancy&amp;page=9,https://www.walmart.com/reviews/product/11027259?limit=20&amp;sort=relevancy&amp;page=7</td>\n",
       "      <td>Way too expensive!</td>\n",
       "      <td>Winded refill</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>VBrit</td>\n",
       "      <td>19800001285</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id   brand  \\\n",
       "897  AV1YGDqsGV-KLJ3adc-O  Windex   \n",
       "\n",
       "                                                                                                                                                                                                                                  categories  \\\n",
       "897  Household Essentials,Cleaning Supplies,Glass Cleaners,Health & Household,Household Supplies,Household Cleaning,Featured Brands,Home And Storage & Org,Thanksgathering,All-purpose Cleaners,Target Restock,Food & Grocery,Glass & Window   \n",
       "\n",
       "                dateAdded           dateUpdated          ean  \\\n",
       "897  2017-07-18T23:46:09Z  2018-02-05T08:34:58Z  19800001285   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                   keys  \\\n",
       "897  019800001285,windex/12972711,windexoriginalglasscleanerrefill676oz2liter/b00192ex24,windexoriginalglasscleanerrefill676oz2liter/b000v9lapy,windexoriginalglasscleanerrefill676oz2liter/b000v9qn1a,windexoriginalglasscleanerrefill676oz2liter/001309400,windexoriginalglasscleanerrefill676oz2liter/1309400,windexoriginalglasscleanerrefill676oz2liter/03249461000p,0019800001285   \n",
       "\n",
       "    manufacturer manufacturerNumber  \\\n",
       "897       Windex           12972711   \n",
       "\n",
       "                                                      name    ...     \\\n",
       "897  Windex Original Glass Cleaner Refill 67.6oz (2 Liter)    ...      \n",
       "\n",
       "    reviews.rating  \\\n",
       "897              5   \n",
       "\n",
       "                                                                                                                                                                                                                                   reviews.sourceURLs  \\\n",
       "897  https://www.walmart.com/reviews/product/11027259?limit=20&sort=relevancy&page=12,https://www.walmart.com/reviews/product/11027259?limit=20&sort=relevancy&page=9,https://www.walmart.com/reviews/product/11027259?limit=20&sort=relevancy&page=7   \n",
       "\n",
       "           reviews.text  reviews.title reviews.userCity reviews.userProvince  \\\n",
       "897  Way too expensive!  Winded refill                                         \n",
       "\n",
       "    reviews.username          upc length sentiment  \n",
       "897            VBrit  19800001285     18    -0.625  \n",
       "\n",
       "[1 rows x 27 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Where sentiment can go wrong\n",
    "# negative sentiment in a 5-star review\n",
    "df[(df['reviews.rating'] == 5) & (df.sentiment < -0.3)].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "      <th>dateAdded</th>\n",
       "      <th>dateUpdated</th>\n",
       "      <th>ean</th>\n",
       "      <th>keys</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>manufacturerNumber</th>\n",
       "      <th>name</th>\n",
       "      <th>...</th>\n",
       "      <th>reviews.rating</th>\n",
       "      <th>reviews.sourceURLs</th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>reviews.title</th>\n",
       "      <th>reviews.userCity</th>\n",
       "      <th>reviews.userProvince</th>\n",
       "      <th>reviews.username</th>\n",
       "      <th>upc</th>\n",
       "      <th>length</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1326</th>\n",
       "      <td>AV1YtGjdglJLPUi8IOfJ</td>\n",
       "      <td>Banana Boat</td>\n",
       "      <td>Personal Care,Makeup,Bronzer,Beauty,Skin Care,Sun &amp; Tanning,Sun Care,Health &amp; Beauty,Sun Protection &amp; Tanning,Sunless Tanning Products,See more Banana Boat Summer Color Tanning lotion,Facial Self Tanners,Face</td>\n",
       "      <td>2017-07-19T02:36:44Z</td>\n",
       "      <td>2018-02-05T11:27:48Z</td>\n",
       "      <td>79656007800</td>\n",
       "      <td>bananaboatsunlesssummercolorselftanninglotionlighttomedium/b00e5qahhq,079656007800,bananaboatsunlesssummercolorselftanninglotionlighttomedium/b001et6yl0,bananaboat/16600894,bananaboat/x10780c0,bananaboatsummercolorselftanninglotionlightmediumcolor6ozs/004603469,0079656007800,bananaboatsummercolorselftanninglotionlightmedium6oz/b001et6yl0,bananaboatsummercolorselftanninglotionlightmedium6oz/301505511828,bananaboatsummercolorselftanninglotionlightmedium6oz/b00e5qahhq,bananaboatsummercolorselft...</td>\n",
       "      <td>Energizer Personal Care</td>\n",
       "      <td>16600894</td>\n",
       "      <td>Banana Boat Sunless Summer Color Self Tanning Lotion, Light To Medium</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.walmart.com/reviews/product/10448308?limit=20&amp;sort=relevancy&amp;page=2</td>\n",
       "      <td>This is a very fast-acting lotion, I'll give it that. My problem is that after using it for about a week (like it says on the bottle), I turned a color that was more of a yellow/orange than anything else. Run away!!!!!!!</td>\n",
       "      <td>TURNS YOU ORANGE</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>jlantz</td>\n",
       "      <td>79656007800</td>\n",
       "      <td>220</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id        brand  \\\n",
       "1326  AV1YtGjdglJLPUi8IOfJ  Banana Boat   \n",
       "\n",
       "                                                                                                                                                                                                            categories  \\\n",
       "1326  Personal Care,Makeup,Bronzer,Beauty,Skin Care,Sun & Tanning,Sun Care,Health & Beauty,Sun Protection & Tanning,Sunless Tanning Products,See more Banana Boat Summer Color Tanning lotion,Facial Self Tanners,Face   \n",
       "\n",
       "                 dateAdded           dateUpdated          ean  \\\n",
       "1326  2017-07-19T02:36:44Z  2018-02-05T11:27:48Z  79656007800   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     keys  \\\n",
       "1326  bananaboatsunlesssummercolorselftanninglotionlighttomedium/b00e5qahhq,079656007800,bananaboatsunlesssummercolorselftanninglotionlighttomedium/b001et6yl0,bananaboat/16600894,bananaboat/x10780c0,bananaboatsummercolorselftanninglotionlightmediumcolor6ozs/004603469,0079656007800,bananaboatsummercolorselftanninglotionlightmedium6oz/b001et6yl0,bananaboatsummercolorselftanninglotionlightmedium6oz/301505511828,bananaboatsummercolorselftanninglotionlightmedium6oz/b00e5qahhq,bananaboatsummercolorselft...   \n",
       "\n",
       "                 manufacturer manufacturerNumber  \\\n",
       "1326  Energizer Personal Care           16600894   \n",
       "\n",
       "                                                                       name  \\\n",
       "1326  Banana Boat Sunless Summer Color Self Tanning Lotion, Light To Medium   \n",
       "\n",
       "        ...    reviews.rating  \\\n",
       "1326    ...                 1   \n",
       "\n",
       "                                                                   reviews.sourceURLs  \\\n",
       "1326  https://www.walmart.com/reviews/product/10448308?limit=20&sort=relevancy&page=2   \n",
       "\n",
       "                                                                                                                                                                                                                      reviews.text  \\\n",
       "1326  This is a very fast-acting lotion, I'll give it that. My problem is that after using it for about a week (like it says on the bottle), I turned a color that was more of a yellow/orange than anything else. Run away!!!!!!!   \n",
       "\n",
       "         reviews.title reviews.userCity reviews.userProvince reviews.username  \\\n",
       "1326  TURNS YOU ORANGE                                                 jlantz   \n",
       "\n",
       "              upc length sentiment  \n",
       "1326  79656007800    220       0.6  \n",
       "\n",
       "[1 rows x 27 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# positive sentiment in a 1-star review\n",
    "df[(df['reviews.rating'] == 1) & (df.sentiment > 0.5)].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the column display width\n",
    "pd.reset_option('max_colwidth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Adding Features to a Document-Term Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DataFrame that only contains the 5-star and 1-star reviews\n",
    "df_best_worst = df[(df['reviews.rating']==5) | (df['reviews.rating']==1)]\n",
    "\n",
    "# define X and y\n",
    "feature_cols = ['reviews.text', 'sentiment'] # cool, useful, funny were put here, Things I don't have\n",
    "X = df_best_worst[feature_cols]\n",
    "y = df_best_worst['reviews.rating']\n",
    "\n",
    "# split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37683, 19919)\n",
      "(12561, 19919)\n"
     ]
    }
   ],
   "source": [
    "# use CountVectorizer with text column only\n",
    "vect = CountVectorizer()\n",
    "X_train_dtm = vect.fit_transform(X_train['reviews.text'])\n",
    "X_test_dtm = vect.transform(X_test['reviews.text'])\n",
    "print (X_train_dtm.shape)\n",
    "print (X_test_dtm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31301</th>\n",
       "      <td>0.116026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40514</th>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42102</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58710</th>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43635</th>\n",
       "      <td>0.433333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment\n",
       "31301   0.116026\n",
       "40514   0.650000\n",
       "42102   0.000000\n",
       "58710   0.466667\n",
       "43635   0.433333"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the other four feature columns that I want to use to predict stars, not just text\n",
    "X_train.drop('reviews.text', axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37683, 1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cast other feature columns to float and convert to a sparse matrix\n",
    "# Why a sparse matrix, because the other matrix is sparse and the data types must match up\n",
    "extra = sp.sparse.csr_matrix(X_train.drop('reviews.text', axis=1).astype(float))\n",
    "extra.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37683, 19920)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine sparse matrices\n",
    "X_train_dtm_extra = sp.sparse.hstack((X_train_dtm, extra))\n",
    "X_train_dtm_extra.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12561, 19920)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# repeat for testing set\n",
    "extra = sp.sparse.csr_matrix(X_test.drop('reviews.text', axis=1).astype(float))\n",
    "X_test_dtm_extra = sp.sparse.hstack((X_test_dtm, extra))\n",
    "X_test_dtm_extra.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9747631557996975\n"
     ]
    }
   ],
   "source": [
    "# use logistic regression with text column only\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_dtm, y_train)\n",
    "y_pred_class = logreg.predict(X_test_dtm)\n",
    "print (metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9751612132791975\n"
     ]
    }
   ],
   "source": [
    "# use logistic regression with all features\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_dtm_extra, y_train)\n",
    "y_pred_class = logreg.predict(X_test_dtm_extra)\n",
    "print (metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Fun TextBlob Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"15 minutes late\")"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spelling correction\n",
    "TextBlob('15 minuets late').correct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('part', 0.9929478138222849), ('parrot', 0.007052186177715092)]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spellcheck\n",
    "Word('parot').spellcheck()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tip laterally',\n",
       " 'enclose with a bank',\n",
       " 'do business with a bank or keep an account at a bank',\n",
       " 'act as the banker in a game or in gambling',\n",
       " 'be in the banking business',\n",
       " 'put into a bank account',\n",
       " 'cover with ashes so to control the rate of burning',\n",
       " 'have confidence or faith in']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# definitions\n",
    "Word('bank').define('v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "- NLP is a gigantic field\n",
    "- Understanding the basics broadens the types of data you can work with\n",
    "- Simple techniques go a long way\n",
    "- Use scikit-learn for NLP whenever possible"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
